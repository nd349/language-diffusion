import os
import argparse
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import AutoModelForMaskedLM, get_scheduler
from datasets import load_from_disk
from accelerate import Accelerator
from tqdm import tqdm
from tokenizer import get_tokenizer



def parse_args():
    ### PARSE COMMAND LINE ARGS ###
    parser = argparse.ArgumentParser(description="RoBERTa Pretraining Arguments on Wikipedia + BookCorpus")
    parser.add_argument(
        "--experiment_name", 
        required=True, 
        type=str
    )

    parser.add_argument(
        "--working_directory", 
        required=True, 
        type=str
    )
    
    ##########################
    ### HUGGINGFACE CONFIG ###
    ##########################

    parser.add_argument(
        "--hf_model_name",
        help="Huggingface model name we want to use for the tokenizer",
        default="answerdotai/ModernBERT-base",
        type=str
    )

    #########################
    ### DATASET ARGUMENTS ###
    #########################

    parser.add_argument(
        "--path_to_prepped_data",
        required=True,
        help="Path to data prepared in `prepare_data.py`",
        type=str
    )

    parser.add_argument(
        "--num_workers",
        help="Number of workers for dataloading",
        default=24, 
        type=int
    )

    ##############################
    ### TRAINING CONFIGURATION ###
    ##############################

    parser.add_argument(
        "--per_gpu_batch_size",
        help="Overall batch size per gpu during training",
        default=16, 
        type=int
    )

    parser.add_argument(
        "--gradient_accumulation_steps",
        help="Splits per_gpu_batch_size by gradient_accumulation_steps",
        default=1, 
        type=int
    )

    parser.add_argument(
        "--num_training_steps", 
        help="Number of training steps to take",
        default=100000,
        type=int
    )

    parser.add_argument(
        "--max_grad_norm",
        help="Max gradient norm used for stabilizing training with gradient clipping",
        default=1.0, 
        type=float
    )

    parser.add_argument(
        "--lr_scheduler_type",
        type=str,
        default="cosine",
        help="The scheduler type to use.",
        choices=["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"],
    )

    parser.add_argument(
        "--num_warmup_steps", 
        type=int, 
        default=1000, 
        help="Number of steps for the warmup in the lr scheduler."
    )

    parser.add_argument(
        "--logging_steps", 
        help="Number of iterations for every log of metrics to wandb",
        default=1,
        type=int
    )

    parser.add_argument(
        "--evaluation_interval", 
        help="Number of iterations for every evaluation and plotting",
        default=2500, 
        type=int
    )

    parser.add_argument(
        "--checkpoint_interval",
        help="Number of iterations for checkpointing",
        default=2500,
        type=int
    )

    parser.add_argument(
        "--learning_rate", 
        help="Max learning rate for all Learning Rate Schedulers", 
        default=5e-5, 
        type=float
    )

    parser.add_argument(
        "--weight_decay",
        help="Weight decay constant for AdamW optimizer", 
        default=0.01, 
        type=float
    )

    #############################
    ### LOGGING CONFIGURATION ###
    #############################
    
    parser.add_argument(
        "--log_wandb", 
        help="Flag to enable logging to wandb",
        default=False, 
        action=argparse.BooleanOptionalAction
    )

    args = parser.parse_args()

    return args

args = parse_args()
path_to_experiment = os.path.join(args.working_directory, args.experiment_name)
accelerator = Accelerator(project_dir=path_to_experiment, 
                          log_with="wandb" if args.log_wandb else None)

if args.log_wandb:
    accelerator.init_trackers(args.experiment_name)

# Tokenizer
tokenizer = get_tokenizer(args.hf_model_name)

# Load model
model = AutoModelForMaskedLM.from_pretrained(args.hf_model_name)
model.resize_token_embeddings(len(tokenizer))

model_parameters = filter(lambda p: p.requires_grad, model.parameters())
params = sum([np.prod(p.size()) for p in model_parameters])
accelerator.print("Number of parameters", params)
mini_batch_size = args.per_gpu_batch_size // args.gradient_accumulation_steps

def collate_function(batch):
    tokens = torch.stack([torch.tensor(b["input_ids"], dtype=torch.long) for b in batch])
    return {"input_ids": tokens}

tokenized_data = load_from_disk(args.path_to_prepped_data)
train_dataloader = DataLoader(tokenized_data["train"], batch_size=mini_batch_size, collate_fn=collate_function, shuffle=True)
eval_dataloader = DataLoader(tokenized_data["test"], batch_size=mini_batch_size, collate_fn=collate_function, shuffle=False)

# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)

scheduler = get_scheduler(
    name=args.lr_scheduler_type,
    optimizer=optimizer,
    num_warmup_steps=args.num_warmup_steps * accelerator.num_processes,
    num_training_steps=args.num_training_steps * accelerator.num_processes,
)

criterion = nn.CrossEntropyLoss(reduction="none") # reduction=none because we want to normalize the loss by randomly sampled t 
model, optimizer, train_dataloader, eval_dataloader, scheduler = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader, scheduler
)

train = True
completed_steps = 0
progress_bar = tqdm(range(completed_steps, args.num_training_steps), disable=not accelerator.is_local_main_process)

while train:
    accumulate_steps = 0
    accumulate_loss = 0
    for batch in train_dataloader:
        # Grab IDs
        input_ids = batch["input_ids"].to(accelerator.device)

        # Random masking strategy
        # Attend to all tokens (need our model to see and predict pad tokens, so we need to train on them)
        batch_size, seq_len = input_ids.shape
        # we want to attend to every token including pad tokens
        attention_mask = torch.ones((batch_size, seq_len), dtype=torch.long, device=accelerator.device) 

        # Random sampling of t to mask tokens
        t = torch.rand(batch_size, 1, device=accelerator.device) # batch_size, 1
        t = t.expand(batch_size, seq_len) # repeat t to make a 2D matrix for each token in each data point (batch_size, seq_len) 
        mask = torch.bernoulli(t).bool() #random masking given the random sampled t
        
        masked_input_ids = input_ids.masked_fill(mask, tokenizer.mask_token_id)
        # we don't need to compute loss for non masked tokens as they are already known. We replace them with -100
        labels = input_ids.masked_fill(~mask, -100) 

        logits = model(input_ids=masked_input_ids, attention_mask=attention_mask)["logits"]

        # (batch_size, seq_len, num_characters)
        num_classes = logits.shape[-1]
        loss = criterion(logits.reshape(batch_size*seq_len, num_classes), labels.flatten())

        # We need to normalize loss by t because loss will be higher for larger t as compared to smaller t.
        loss = loss.reshape(batch_size, seq_len) / t
        loss = loss.mean()

        loss = loss / args.gradient_accumulation_steps
        accumulate_loss += loss
        accelerator.backward(loss)
        
        accumulate_steps += 1
        if accumulate_steps % args.gradient_accumulation_steps == 0:
            # Update the model after every args.gradient_accumulation_steps steps.
            accelerator.clip_grad_norm_(model.parameters(), args.max_grad_norm)
            optimizer.step()
            optimizer.zero_grad(set_to_none=True)
            scheduler.step()
            if completed_steps % args.logging_steps == 0:
                accumulate_loss = accumulate_loss.detach()
                if accelerator.state.num_processes > 1:
                    accumulate_loss = torch.mean(accelerator.gather_for_metrics(accumulate_loss))
                log = {
                    "train_loss": accumulate_loss,
                    "learning_rate": scheduler.get_last_lr()[0]
                }
                logging_string = f"[{completed_steps}/{args.num_training_steps}] Training Loss: {accumulate_loss}"
                if accelerator.is_main_process:
                    progress_bar.write(logging_string)
                
                if args.log_wandb:
                    accelerator.log(log, step=completed_steps) 
            
            # Evaluation loop
            if completed_steps % args.evaluation_interval == 0:
                if accelerator.is_main_process:
                    progress_bar.write("Evaluating Model!!")
                
                model.eval()
                log = {"val_loss": 0}
                # Iterate Data
                num_losses = 0
                for batch in eval_dataloader:
                    # Grab IDs
                    input_ids = batch["input_ids"].to(accelerator.device)

                    # Random masking strategy
                    # Attend to all tokens (need our model to see and predict pad tokens, so we need to train on them)
                    batch_size, seq_len = input_ids.shape
                    # we want to attend to every token including pad tokens
                    attention_mask = torch.ones((batch_size, seq_len), dtype=torch.long, device=accelerator.device) 

                    # Random sampling of t to mask tokens
                    t = torch.rand(batch_size, 1, device=accelerator.device) # batch_size, 1
                    t = t.expand(batch_size, seq_len) # repeat t to make a 2D matrix for each token in each data point (batch_size, seq_len) 
                    mask = torch.bernoulli(t).bool() #random masking given the random sampled t
                    
                    masked_input_ids = input_ids.masked_fill(mask, tokenizer.mask_token_id)
                    # we don't need to compute loss for non masked tokens as they are already known. We replace them with -100
                    labels = input_ids.masked_fill(~mask, -100) 

                    # Compute logits
                    with torch.inference_mode():
                        logits = model(input_ids=masked_input_ids, attention_mask=attention_mask)["logits"]
                    
                    # Compute loss
                    num_classes = logits.shape[-1]
                    loss = criterion(logits.reshape(batch_size*seq_len, num_classes),
                                     labels.flatten())
                    
                    # Scale loss by t
                    loss = loss.reshape(batch_size, seq_len) / t
                    loss = loss.mean()

                    loss = loss.detach()
                    if accelerator.num_processes > 1:
                        loss = torch.mean(accelerator.gather_for_metrics(loss))

                    # Add to our Logs
                    log["val_loss"] += loss
                    num_losses += 1

                # Divide loss by num_losses
                log["val_loss"] = log["val_loss"] / num_losses

                logging_string = f"[{completed_steps}/{args.num_training_steps}] Validation Loss: {log["val_loss"]}"
    
                # Print out Log
                if accelerator.is_main_process:
                    progress_bar.write(logging_string)
                
                if args.log_wandb:
                    accelerator.log(log, step=completed_steps)

                model.train()

            # Checkpoint Model (Only need main process for this)
            if (completed_steps % args.checkpoint_interval == 0):
                
                # Save Checkpoint
                path_to_checkpoint = os.path.join(path_to_experiment, f"checkpoint_{completed_steps}")

                if accelerator.is_main_process:
                    progress_bar.write(f"Saving Checkpoint to {path_to_checkpoint}")

                # Make sure that all processes have caught up before saving checkpoint!
                accelerator.wait_for_everyone()

                # Save checkpoint using only the main process
                if accelerator.is_main_process:
                    accelerator.save_state(output_dir=path_to_checkpoint)
            
            if completed_steps >= args.num_training_steps:
                train = False
                if accelerator.is_main_process:
                    progress_bar.write("Completed Training!!")
                break

            # Iterate Progress Bar and Completed Steps
            completed_steps += 1
            progress_bar.update(1)

            # Reset Loss Accumulate For Next Accumulation
            accumulate_loss = 0

path_to_checkpoint = os.path.join(path_to_experiment, f"final_model")
accelerator.save_state(output_dir=path_to_checkpoint)
accelerator.end_training()



